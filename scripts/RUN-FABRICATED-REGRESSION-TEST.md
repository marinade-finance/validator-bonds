# Fabricated Regression Test for Settlement Unification

## Purpose

This test validates that the **unified settlement pipeline** (on the `refactoring-unification` branch) produces results identical to the **old separate pipelines** (on `main`).

On `main`, settlement distribution used three separate CLIs:

- `bid-distribution-cli` -- SAM bidding settlements only
- `bid-psr-distribution-cli` -- PSR (Protected Staking Rewards) settlements only
- `institutional-distribution-cli` -- institutional payout settlements

Each produced its own settlement collection and merkle tree file.

On the refactored branch, SAM and PSR are **unified** into a single `bid-distribution-cli` invocation, and merkle trees are generated by a new `merkle-generator-cli` that merges claims per vote account across settlement sources.

The test creates **fabricated but realistic input data** (no GCS or network access needed), runs both the old and new pipelines, and compares outputs using the existing `regression-test-settlements.sh` harness.

## What the test covers

Five fabricated validators exercise different settlement paths:

| Validator | Scenario                                                            | Expected Settlements                  |
| --------- | ------------------------------------------------------------------- | ------------------------------------- |
| A         | Normal SAM bidder, no issues                                        | Bidding                               |
| B         | SAM bidder + 26% downtime                                           | Bidding + DowntimeRevenueImpact (PSR) |
| C         | SAM bidder + commission increase (0% -> 5% inflation, 0% -> 8% MEV) | Bidding + CommissionSamIncrease (PSR) |
| D         | No SAM bid, non-whitelisted stake authority                         | None                                  |
| E         | Institutional staker                                                | InstitutionalPayout                   |

Validators B and C are the interesting cases: they have **both** SAM and PSR settlements for the same vote account. In the old pipeline these lived in separate files; in the new pipeline they are merged into a single settlement collection and a unified merkle tree.

The regression checks performed (by `regression-test-settlements.sh`):

1. **Settlement count**: old SAM count + old PSR count == new unified count
2. **Total claims amount**: sum across old files == sum across new file
3. **Per-vote-account claims**: every vote account's total matches
4. **Merkle roots**: SAM-only vote accounts have identical roots; PSR-overlapping accounts are expected to differ (merged tree)
5. **Per-funder amounts**: settlement collection per-vote per-funder totals == merkle tree `funding_sources`
6. **Institutional settlements**: claims, merkle roots, and per-funder amounts match exactly

## Files

```
scripts/
  generate-fabricated-test-data.py    # Generates all input JSON files
  run-fabricated-regression-test.sh   # Orchestrates the full test
  regression-test-settlements.sh      # Comparison harness (pre-existing)
  RUN-FABRICATED-REGRESSION-TEST.md   # This file
```

## Prerequisites

- Python 3 with the `base58` package (`pip install base58`) -- only needed if regenerating pubkeys; the script has them hardcoded
- Rust toolchain (`cargo build`)
- `jq` (used by the regression test harness)
- Clean git working tree (the script stashes uncommitted changes temporarily)

## Usage

### Full end-to-end run (recommended first time)

```bash
./scripts/run-fabricated-regression-test.sh
```

This performs all three steps:

1. Generates fabricated input data into `regression-data-fabricated/99999/inputs/`
2. Checks out `main`, builds old CLIs, runs them to produce `expected/` outputs
3. Switches back to the current branch, builds new CLIs, runs `regression-test-settlements.sh` to produce `actual/` and compare

### Step-by-step run

If you want more control (e.g., the build takes a while and you don't want to redo everything):

```bash
# Step 1+2: Generate inputs and expected outputs only (does NOT run new pipeline)
./scripts/run-fabricated-regression-test.sh --only-generate

# Step 3: Run comparison only (reuses existing inputs and expected outputs)
./scripts/run-fabricated-regression-test.sh --skip-generate --skip-expected
```

### Options

| Flag              | Description                                                         |
| ----------------- | ------------------------------------------------------------------- |
| `--data-dir DIR`  | Where to store test data (default: `./regression-data-fabricated`)  |
| `--skip-generate` | Skip input data generation, reuse existing files                    |
| `--skip-expected` | Skip building/running on `main`, reuse existing `expected/` outputs |
| `--only-generate` | Generate inputs + expected outputs, then stop (no new pipeline run) |

### Regenerating only the input data

```bash
python3 scripts/generate-fabricated-test-data.py --output-dir ./regression-data-fabricated/99999/inputs
```

## Directory layout

After a full run, the data directory looks like:

```
regression-data-fabricated/
  99999/
    inputs/
      stakes.json                          # Stake accounts (8 accounts across 5 validators)
      sam-scores.json                      # SAM auction scores (3 validators)
      validators.json                      # Validator metadata (credits, commissions)
      evaluation.json                      # Revenue expectations (expected vs actual PMPE)
      rewards/
        inflation.json                     # Per-stake-account inflation rewards
        mev.json                           # Per-stake-account MEV rewards
        jito_priority_fee.json             # Per-stake-account Jito priority fees
        validators_inflation.json          # Per-validator inflation commission rewards
        validators_mev.json                # Per-validator MEV commission rewards
        validators_blocks.json             # Per-validator block rewards
      institutional/
        institutional-payouts.json         # Institutional payout data
        stakes.json                        # Stake snapshot for institutional

    expected/                              # Produced by OLD pipeline on main
      bid-distribution-settlements.json              # SAM-only settlements
      bid-psr-distribution-settlements.json          # PSR-only settlements
      bid-distribution-settlement-merkle-trees.json  # SAM merkle trees
      bid-psr-distribution-settlement-merkle-trees.json  # PSR merkle trees
      institutional-distribution-settlements.json
      institutional-distribution-settlement-merkle-trees.json

    actual/                                # Produced by NEW pipeline on current branch
      bid-distribution-settlements.json    # Unified SAM+PSR settlements
      unified-merkle-trees.json            # Unified merkle trees
      institutional-distribution-settlements.json
      institutional-merkle-trees.json
```

## How the git branch switching works

The runner script needs to build on two different branches. It handles this safely:

1. Stashes any uncommitted changes
2. Checks out `main` and builds old CLIs
3. Runs old CLIs to produce `expected/` outputs
4. Switches back to the original branch and restores stashed changes
5. Builds new CLIs and runs the comparison

A cleanup trap ensures the branch is restored even if the script fails partway through.

## Interpreting results

The regression test prints a summary table:

```
Epoch   | Bid Claims  | Bid Merkle  | Inst Claims | Inst Merkle | Status
--------|-------------|-------------|-------------|-------------|-------
99999   | MATCH       | MATCH       | MATCH       | MATCH       | PASS
```

- **MATCH**: Old and new pipelines produce equivalent results
- **DIFFER**: A mismatch was found (details printed above the summary)
- **SKIP**: Missing input/expected files (shouldn't happen with fabricated data)
- **ERROR**: A CLI crashed or produced unparseable output

For **Bid Merkle**, SAM-only vote accounts (Validator A) should have identical merkle roots. Vote accounts with both SAM and PSR settlements (Validators B, C) will have different roots because the new pipeline merges their claims into a single tree -- this is expected and reported as an INFO message, not a failure.

## Extending the test data

To add more scenarios, edit `scripts/generate-fabricated-test-data.py`:

1. Add new pubkey constants (use `hashlib.sha256(seed).digest()` + `base58.b58encode()` for valid keys)
2. Add stake accounts to `generate_stakes_json()`
3. Add SAM scores to `generate_sam_scores_json()` if the validator participates in the auction
4. Add validator metadata to `generate_validators_json()` (credits, commissions)
5. Add revenue expectations to `generate_evaluation_json()` (set `actualNonBidPmpe` < `expectedNonBidPmpe` for PSR triggers)
6. Add reward entries to the reward generation functions
7. Re-run the full test
